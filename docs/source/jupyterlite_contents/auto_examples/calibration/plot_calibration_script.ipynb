{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-plots examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import scikitplot`can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-plots/scikit-plots/issues/new/choose) about it.\n</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# JupyterLite-specific code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n# plot_calibration with examples\n\nAn example showing the :py:func:`~scikitplot.api.metrics.plot_calibration` function\nused by a scikit-learn classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Authors: The scikit-plots developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "# run: Python scripts and shows any outputs directly in the notebook.\n",
    "# %run ./examples/calibration/plot_calibration_script.py\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import numpy as np; np.random.seed(0)  # reproducibility\n",
    "# importing pylab or pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import scikit-plot\n",
    "import scikitplot as sp\n",
    "\n",
    "# Load the data\n",
    "X, y = make_classification(\n",
    "  n_samples=100000,\n",
    "  n_features=20,\n",
    "  n_informative=4,\n",
    "  n_redundant=2,\n",
    "  n_repeated=0,\n",
    "  n_classes=3,\n",
    "  n_clusters_per_class=2,\n",
    "  random_state=0\n",
    ")\n",
    "X_train, y_train, X_val, y_val = X[:1000], y[:1000], X[1000:], y[1000:]\n",
    "\n",
    "# Create an instance of the LogisticRegression\n",
    "lr_probas = LogisticRegression(max_iter=int(1e5), random_state=0).fit(X_train, y_train).predict_proba(X_val)\n",
    "nb_probas = GaussianNB().fit(X_train, y_train).predict_proba(X_val)\n",
    "svc_scores = LinearSVC().fit(X_train, y_train).decision_function(X_val)\n",
    "svc_isotonic = CalibratedClassifierCV(LinearSVC(), cv=2, method=\"isotonic\").fit(X_train, y_train).predict_proba(X_val)\n",
    "svc_sigmoid = CalibratedClassifierCV(LinearSVC(), cv=2, method=\"sigmoid\").fit(X_train, y_train).predict_proba(X_val)\n",
    "rf_probas = RandomForestClassifier(random_state=0).fit(X_train, y_train).predict_proba(X_val)\n",
    "\n",
    "probas_dict = {\n",
    "  LogisticRegression(): lr_probas,\n",
    "  # GaussianNB(): nb_probas,\n",
    "  \"LinearSVC() + MinMax\": svc_scores,\n",
    "  \"LinearSVC() + Isotonic\": svc_isotonic,\n",
    "  \"LinearSVC() + Sigmoid\": svc_sigmoid,\n",
    "  # RandomForestClassifier(): rf_probas,\n",
    "}\n",
    "# Plot!\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax = sp.metrics.plot_calibration(\n",
    "  y_val,\n",
    "  y_probas_list=probas_dict.values(),\n",
    "  estimator_names=probas_dict.keys(),\n",
    "  ax=ax,\n",
    ")\n",
    "\n",
    "# Adjust layout to make sure everything fits\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot with a filename based on the current script's name\n",
    "# sp.api._utils.save_plot()\n",
    "\n",
    "# Display the plot\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. admonition:: Interpretation\n\n    Primary Use: Evaluating probabilistic classifiers by comparing predicted probabilities to observed frequencies of the positive class.\n\n    Goal: To assess how well the predicted probabilities align with the actual outcomes, identifying if a model is well-calibrated, overconfident, or underconfident.\n\n    Typical Characteristics:\n\n    - X-axis: Predicted probability (e.g., in bins from 0 to 1).\n    - Y-axis: Observed frequency of the positive class within each bin.\n    - Reference line (diagonal at 45Â°): Represents perfect calibration, where predicted probabilities match observed frequencies.\n\n.. tags::\n\n   model-type: classification\n   model-workflow: model evaluation\n   component: fitted model\n   plot-type: line\n   plot-type: calibration plot\n   level: beginner\n   purpose: showcase\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
